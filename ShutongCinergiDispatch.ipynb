{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Discovery Studio Jupyter Notebook Dispatcher\n",
    "\n",
    "## 1. Execute the cells below to get parameters from DDS and select a notebook for processing ###\n",
    "\n",
    "Example call with Document ID from DDS: CinergiDispatch.ipynb?documentId=61cc7f6afb5246d2be41811e94a1a8ea\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check if the parameters are correct\n",
    "from __future__ import print_function\n",
    "import ntpath\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import webbrowser\n",
    "from lxml import etree  #supposed to be better than xml.etree\n",
    "\n",
    "documentID=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "function getQueryStringValue (key)\n",
       "{  \n",
       "    return unescape(window.location.search.replace(new RegExp(\"^(?:.*[&\\\\?]\" + escape(key).replace(/[\\.\\+\\*]/g, \"\\\\$&\") + \"(?:\\\\=([^&]*))?)?.*$\", \"i\"), \"$1\"));\n",
       "}\n",
       "IPython.notebook.kernel.execute(\"documentID='\".concat(getQueryStringValue(\"documentId\")).concat(\"'\"));\n",
       "IPython.notebook.kernel.execute(\"user='\".concat(getQueryStringValue(\"user\")).concat(\"'\"));\n",
       "IPython.notebook.kernel.execute(\"full_notebook_url='\" + window.location + \"'\"); "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "function getQueryStringValue (key)\n",
    "{  \n",
    "    return unescape(window.location.search.replace(new RegExp(\"^(?:.*[&\\\\?]\" + escape(key).replace(/[\\.\\+\\*]/g, \"\\\\$&\") + \"(?:\\\\=([^&]*))?)?.*$\", \"i\"), \"$1\"));\n",
    "}\n",
    "IPython.notebook.kernel.execute(\"documentID='\".concat(getQueryStringValue(\"documentId\")).concat(\"'\"));\n",
    "IPython.notebook.kernel.execute(\"user='\".concat(getQueryStringValue(\"user\")).concat(\"'\"));\n",
    "IPython.notebook.kernel.execute(\"full_notebook_url='\" + window.location + \"'\"); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Print out parameters passed to Jupyter: ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# use hardwired values for testing\n",
    "# these only get used if no documentID is passes as an argument when \n",
    "#   opening the notebook (per getQueryStringValue javascript function at start)\n",
    "catalogURL = \"http://datadiscoverystudio.org/geoportal/\"\n",
    "if (len(documentID)==0):\n",
    "    #documentID=\"e3619c5df2644204b67f51f48525a0b1\"    #NGDS wfs\n",
    "    #documentID=\"4db8156abb6d4119aa5c35aa39514b42\"   #sciencebase WFS\n",
    "    #documentID=\"61cc7f6afb5246d2be41811e94a1a8ea\"   #ndbc data\n",
    "    documentID=\"de5383bf941d4d60ae9443bd7ffa9a33\"   #Magic data\n",
    "    #documentID=\"b20f8f12ef594520abb0e5efbcd891fe\"   #nwis qwdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  \n",
      "DocumentID:  de5383bf941d4d60ae9443bd7ffa9a33\n",
      "Full notebook URL:  http://localhost:8889/notebooks/jupyter-dispatchtests/ShutongCinergiDispatch.ipynb\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url_partitioned = full_notebook_url.partition('/CinergiDispatch')\n",
    "base_url = url_partitioned[0];\n",
    "\n",
    "print(\"User: \",user)\n",
    "print(\"DocumentID: \", documentID)\n",
    "# print(\"full notebook url partition\", url_partitioned)\n",
    "print(\"Full notebook URL: \", full_notebook_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import requests\n",
    "\n",
    "#construct url for metadata\n",
    "catalogURL = \"http://datadiscoverystudio.org/geoportal/\"\n",
    "metadataURLx=catalogURL + 'rest/metadata/item/' + documentID + '/xml'\n",
    "metadata = requests.get(metadataURLx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parsing the xml metadata into a dict\n",
    "P.S. Repetitive keys have its key value pair stored in a list at its level of hiearchy in the dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "from collections import OrderedDict\n",
    "\n",
    "metadata_dict = xmltodict.parse(metadata.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set up namespace map for ISO metadata\n",
    "NSMAP = {\"gmi\":\"http://www.isotc211.org/2005/gmi\" ,\n",
    "    \"gco\":\"http://www.isotc211.org/2005/gco\" ,\n",
    "    \"gmd\":\"http://www.isotc211.org/2005/gmd\" ,\n",
    "    \"gml\":\"http://www.opengis.net/gml\" ,\n",
    "    \"gmx\":\"http://www.isotc211.org/2005/gmx\" ,\n",
    "    \"gts\":\"http://www.isotc211.org/2005/gts\" ,\n",
    "    \"srv\":\"http://www.isotc211.org/2005/srv\" ,\n",
    "    \"xlink\":\"http://www.w3.org/1999/xlink\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#tree is an element tree\n",
    "tree = etree.parse(metadataURLx)\n",
    "#root = etree.tostring(tree.getroot())\n",
    "root = tree.getroot()\n",
    "docinfo = tree.docinfo\n",
    "print(docinfo.xml_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=tree.find(\"//gmd:identificationInfo//gmd:title/gco:CharacterString\",namespaces=NSMAP).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#title of the dataset, not sure how useful\n",
    "#title = metadata_dict['gmi:MI_Metadata']['gmd:identificationInfo']['gmd:MD_DataIdentification']['gmd:citation']['gmd:CI_Citation']['gmd:title']['gco:CharacterString']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASCII\n"
     ]
    }
   ],
   "source": [
    "for  dist in tree.getiterator(\"{http://www.isotc211.org/2005/gmd}MD_Distribution\"):\n",
    "    if dist.find(\"gmd:distributionFormat/gmd:MD_Format/gmd:name/gco:CharacterString\",namespaces=NSMAP) is not None: \n",
    "        # this code is not handling multiple formats under a distribution at this point. \n",
    "        # have to consider how to deal with binding between formats and digital transfer options\n",
    "        dist_format = dist.find(\"gmd:distributionFormat/gmd:MD_Format/gmd:name/gco:CharacterString\",namespaces=NSMAP).text\n",
    "    else:\n",
    "        dist_format = ''\n",
    "    print(distribute_format)\n",
    "    if dist.find(\"gmd:distributor/gmd:MD_Distributor//gmd:organisationName/.\",namespaces=NSMAP) is not None:\n",
    "        distorg =dist.find(\"gmd:distributor/gmd:MD_Distributor//gmd:organisationName/.\",namespaces=NSMAP)\n",
    "    else:\n",
    "        distorg = ''\n",
    "        \n",
    "    if dist.find(\"gmd:distributor/gmd:MD_Distributor//gmd:MD_DigitalTransferOptions//gmd:CI_OnlineResource.\",namespaces=NSMAP) is not None:\n",
    "        distonline =dist.find(\"gmd:distributor/gmd:MD_Distributor//gmd:MD_DigitalTransferOptions//gmd:CI_OnlineResource\",namespaces=NSMAP)\n",
    "    else:\n",
    "        distonline = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#subtree involving meta data distribution information\n",
    "\n",
    "# this is problematic because it depends on use of the standard namespace prefixes, which\n",
    "#  is not required by xml\n",
    "md_dist = metadata_dict['gmi:MI_Metadata']['gmd:distributionInfo']['gmd:MD_Distribution']\n",
    "distribute_format = md_dist['gmd:distributionFormat']['gmd:MD_Format']['gmd:name']['gco:CharacterString']\n",
    "distributor = md_dist['gmd:distributor'][0]['gmd:MD_Distributor']['gmd:distributorContact']['gmd:CI_ResponsibleParty']['gmd:organisationName']['gco:CharacterString']\n",
    "dist_landing = md_dist['gmd:distributor'][0]['gmd:MD_Distributor']['gmd:distributorTransferOptions']['gmd:MD_DigitalTransferOptions']['gmd:onLine']['gmd:CI_OnlineResource']['gmd:linkage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map the properties of metadata to suggested tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#look up the combination of metadata features in a table and map the combination to potential tokens\n",
    "def md_to_token(df, *features):\n",
    "    #look up the combination of the features\n",
    "    #precondition : features comes in order, if feature for corresponding column does not exist, leave it as null\n",
    "    featurelist = list(features)\n",
    "    assert len(featurelist) <= (df.shape[1] - 1), 'feature space dimension mismatch'\n",
    "    sets = []\n",
    "    col_indx = 0\n",
    "    non_empty_sets = 0\n",
    "    for feature in featurelist:\n",
    "        index_set = set(df.loc[df.iloc[:, col_indx] == feature].index)\n",
    "        sets += [index_set]\n",
    "        if (len(index_set) > 0):\n",
    "            non_empty_sets += 1\n",
    "        col_indx = col_indx + 1\n",
    "    \n",
    "    #if the feature set is complete\n",
    "    if non_empty_sets == df.shape[1] - 1:\n",
    "        idx = list(set.intersection(*sets))\n",
    "        return list(df['tokens'].loc[idx])\n",
    "    \n",
    "    #the feature set is not complete, suggest all possibilities\n",
    "    else:\n",
    "        idx = list(set.union(*sets))\n",
    "        return list(df['tokens'].loc[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map tokens to the notebook url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#map the given set to tokens to a set of urls\n",
    "def token_to_url(tokens, df):\n",
    "    #tokens is a list of string tokens\n",
    "    #assume the token space of this url-mapping df is the same as the one of the token mapping df\n",
    "    urls = list(df.loc[df['tokens'].apply(lambda x: x in tokens)]['url'])\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#not really used\n",
    "def token_to_desc(tokens, df):\n",
    "    #df is a mapping table from tokens to labels and descriptions\n",
    "    #return a dict with keys as tokens and values as another dict - \n",
    "    #whose keys are descprtion and label and values are corresponding values\n",
    "    subset = df.loc[df['tokens'].apply(lambda x: x in tokens)].set_index('tokens')\n",
    "    return subset.to_dict('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo, for testing.\n",
    "\n",
    "an example token map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_token_map = pd.DataFrame({'feature1': ['a', 'b', 'c', 'b'],\n",
    "                             'feature2': ['d', 'e', 'f', 'x'],\n",
    "                             'feature3': ['g', 'h', 'i', 'y'],\n",
    "                             'tokens': [1, 2, 3, 4]})\n",
    "md_token_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_url_map = pd.DataFrame({'tokens': [1, 2, 3, 4],\n",
    "                             'url': ['url1', 'url2', 'url3', 'url4']})\n",
    "token_url_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_desc_map = pd.DataFrame({'tokens': [1, 2, 3, 4],\n",
    "                              'label': ['label1', 'label2', 'label3', 'label4'],\n",
    "                              'description': ['desc1', 'desc2', 'desc3', 'desc4']})\n",
    "token_desc_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_desc_map = pd.merge(left = token_url_map, right = token_desc_map, on = 'tokens')[['url', 'label', 'description']].set_index('url')\n",
    "url_desc_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "suppose I attain feature combination of [b, e, h]. Actual datasets should have more combinations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1 = 'b'\n",
    "feature2 = 'e'\n",
    "feature3 = 'h'\n",
    "tokens = md_to_token(md_token_map, feature1, feature2, feature3)\n",
    "urls = token_to_url(tokens, token_url_map)\n",
    "token_info = token_to_desc(tokens, token_desc_map)\n",
    "\n",
    "test_menu = OrderedDict()\n",
    "for url in urls:\n",
    "    menu_label = dict(url_desc_map.loc[url])['label']\n",
    "    if menu_label in test_menu.keys():\n",
    "        menu_label = menu_label + '1'\n",
    "    test_menu[menu_label] = url\n",
    "def wrapper(menu):\n",
    "    return menu\n",
    "test_out = interact(wrapper, menu = test_menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example that returns >1 url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature4 = 'b'\n",
    "feature5 = np.nan\n",
    "feature6 = np.nan\n",
    "tokens2 = md_to_token(md_token_map, feature4, feature5, feature6)\n",
    "urls2 = token_to_url(tokens2, token_url_map)\n",
    "\n",
    "test_menu2 = OrderedDict()\n",
    "for url in urls2:\n",
    "    menu_label = dict(url_desc_map.loc[url])['label']\n",
    "    if menu_label in test_menu2.keys():\n",
    "        menu_label = menu_label + '1'\n",
    "    test_menu2[menu_label] = url\n",
    "def wrapper(menu):\n",
    "    return menu\n",
    "test_out2 = interact(wrapper, menu = test_menu2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Open the URL of the selected notebook ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_nb_name = nb_menu[out.widget.result]\n",
    "url1 = ('{base_url}/operations/{nb_name}?'+'documentId='+documentID+'&'+'user='+user).format(base_url=base_url, nb_name=chosen_nb_name)\n",
    "\n",
    "#webbrowser.open(url1)\n",
    "webbrowser.open_new(url1)\n",
    "print(\"CLICK TO OPEN THE URL: \", url1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python36-anaconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
